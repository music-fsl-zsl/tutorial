{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Few-Shot Instrument Classifier\n",
    "\n",
    "In this tutorial, we will be training a few-shot learning model for music information retrieval. We will use the PyTorch framework and the [PyTorch Lightning](https://www.pytorchlightning.ai/) library.\n",
    "\n",
    "In [previous chapters](/fsl-example/intro.md), we introduced several essential concepts for training a few-shot learning model. We learned how to create a [class-conditional dataset](/fsl-example/datasets.html) for few-shot learning, using the TinySOL dataset. \n",
    "We also learned how to construct few-shot learning episodes from a class-conditional dataset, using an [episode dataset](/fsl-example/episodes.html). Finally, we learned how to create a [Prototypical Network](/fsl-example/models.html), given any backbone model architecture. \n",
    "\n",
    "Now, it's time to put all these pieces together and train our few-shot model. \n",
    "\n",
    "We will train a few-shot instrument classifier to solve 5-way, 5-shot classification tasks. This means that the model will be trained to classify 5 different instrument classes at a time, using 5 support examples per class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements (hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch\n",
    "!pip install pytorch-lightning\n",
    "!pip install numpy\n",
    "!pip install --no-cache-dir --upgrade music-fsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from music_fsl.backbone import Backbone\n",
    "from music_fsl.data import TinySOL, EpisodeDataset\n",
    "from music_fsl.protonet import PrototypicalNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We'll define some hyperparameters below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000 # sample rate of the audio\n",
    "n_way= 5 # number of classes per episode\n",
    "n_support = 5 # number of support examples per class\n",
    "n_query = 20 # number of samples per class to use as query\n",
    "n_train_episodes = int(50000) # number of episodes to generate for training\n",
    "n_val_episodes = 100 # number of episodes to generate for validation\n",
    "num_workers = 10 # number of workers to use for data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Split the dataset into train and test sets\n",
    "\n",
    "Since we're training a few-shot model to generalize to unseen instrument classes, we'll need to make a class-conditional split of the TinySOL dataset. This means we'll keep most of the instrument classes in the training set, and leave out a few for the test set. \n",
    "\n",
    "We'll use an arbitrary split, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_INSTRUMENTS = [\n",
    "    'French Horn', \n",
    "    'Violin', \n",
    "    'Flute', \n",
    "    'Contrabass', \n",
    "    'Trombone', \n",
    "    'Cello', \n",
    "    'Clarinet in Bb', \n",
    "    'Oboe',\n",
    "    'Accordion'\n",
    "]\n",
    "\n",
    "TEST_INSTRUMENTS = [\n",
    "    'Bassoon',\n",
    "    'Viola',\n",
    "    'Trumpet in C',\n",
    "    'Bass Tuba',\n",
    "    'Alto Saxophone'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets\n",
    "\n",
    "Let's load the train and test sets, using the class-conditional `TinySOL` dataset class we implemented in the [previous chapter](/fsl-examples/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Downloading ['audio', 'annotations'] to /home/hugo/mir_datasets/tinysol\n",
      "INFO: [audio] downloading TinySOL.tar.gz\n",
      "INFO: /home/hugo/mir_datasets/tinysol/audio/TinySOL.tar.gz already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n",
      "INFO: [annotations] downloading TinySOL_metadata.csv\n",
      "INFO: /home/hugo/mir_datasets/tinysol/annotation/TinySOL_metadata.csv already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n",
      "INFO: Downloading ['audio', 'annotations'] to /home/hugo/mir_datasets/tinysol\n",
      "INFO: [audio] downloading TinySOL.tar.gz\n",
      "INFO: /home/hugo/mir_datasets/tinysol/audio/TinySOL.tar.gz already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n",
      "INFO: [annotations] downloading TinySOL_metadata.csv\n",
      "INFO: /home/hugo/mir_datasets/tinysol/annotation/TinySOL_metadata.csv already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n"
     ]
    }
   ],
   "source": [
    "# initialize the datasets\n",
    "train_data = TinySOL(\n",
    "    instruments=TRAIN_INSTRUMENTS, \n",
    "    sample_rate=sample_rate\n",
    ")\n",
    "\n",
    "val_data = TinySOL(\n",
    "    instruments=TEST_INSTRUMENTS, \n",
    "    sample_rate=sample_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Episode Datasets\n",
    "\n",
    "Next, we'll initialize the episode datasets for the train and test sets.\n",
    "\n",
    "As we learned in the [previous chapter](/fsl-example/episodes.html), we can use the `EpisodeDataset` class to create a few-shot learning episode from a dataset. The `EpisodeDataset` wraps around the `ClassConditionalDataset` to retrieve few-shot learning episodes, given the dataset and the number of classes and support examples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the episode datasets\n",
    "train_episodes = EpisodeDataset(\n",
    "    dataset=train_data, \n",
    "    n_way=n_way, \n",
    "    n_support=n_support,\n",
    "    n_query=n_query, \n",
    "    n_episodes=n_train_episodes\n",
    ")\n",
    "\n",
    "val_episodes = EpisodeDataset(\n",
    "    dataset=val_data, \n",
    "    n_way=n_way, \n",
    "    n_support=n_support,\n",
    "    n_query=n_query, \n",
    "    n_episodes=n_val_episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders\n",
    "\n",
    "We can pass the episode datasets to a PyTorch `DataLoader` to create a dataloader for the train and test sets. Since our episodes already contained a batch of examples in the support and query sets, we set the batch size to `None` in the dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_episodes, \n",
    "    batch_size=None,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_episodes, \n",
    "    batch_size=None,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Prototypical Network\n",
    "\n",
    "Let's instantiate the prototypical network we coded up in the [last chapter](/fsl-example/models.html). As a reminder, the prototypical network will take the support and query sets as input, and will return a set of logits for each query example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrototypicalNet(\n",
       "  (backbone): Backbone(\n",
       "    (melspec): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (conv1): ConvBlock(\n",
       "      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (gn): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (relu): ReLU()\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): ConvBlock(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (gn): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "      (relu): ReLU()\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): ConvBlock(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (gn): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "      (relu): ReLU()\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv4): ConvBlock(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (gn): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "      (relu): ReLU()\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv5): ConvBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "      (gn): GroupNorm(128, 512, eps=1e-05, affine=True)\n",
       "      (relu): ReLU()\n",
       "      (maxpool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build models\n",
    "backbone = Backbone(sample_rate=sample_rate)\n",
    "protonet = PrototypicalNet(backbone)\n",
    "\n",
    "protonet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a LightningModule for Training\n",
    "\n",
    "Next, we will define a PyTorch Lightning `LightningModule` to train our few-shot learning model. We will name this module `FewShotLearner`. The `LightningModule` is a PyTorch Lightning class that provides several useful methods for training, validation, and testing.\n",
    "\n",
    "Because there is an abundance of fantastic Pytorch Lightning tutorials, we will not go into too much detail about the `LightningModule`. If you are interested in learning more about PyTorch Lightning, check out the [PyTorch Lightning Tutorials](https://pytorch-lightning.readthedocs.io/en/stable/tutorials.html). \n",
    "\n",
    "\n",
    "### Setting up the LightningModule\n",
    "\n",
    "In this step, we will define the `FewShotLearner` class, which is a PyTorch Lightning `LightningModule`. This class will be responsible for training our few-shot learning model. It takes a few arguments in its constructor, including the `PrototypicalNet` model that we defined earlier and a learning rate for the optimizer. We also define a loss function and some evaluation metrics in the constructor. In this case, we use the cross-entropy loss and accuracy as our loss and metrics, respectively. The `LightningModule` provides several useful methods for training, validation, and testing, making it a convenient way to train our few-shot learning model.\n",
    "\n",
    "\n",
    "```python\n",
    "class FewShotLearner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "        protonet: nn.Module, \n",
    "        learning_rate: float = 1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.protonet = protonet\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.metrics = nn.ModuleDict({\n",
    "            'accuracy': Accuracy()\n",
    "        })\n",
    "```\n",
    "\n",
    "### The Training (And Eval) Step\n",
    "\n",
    "In the `FewShotLearner` class, we'll define a `step` method that performs the actual training `step`. This method takes in a batch of data, the batch index, and a string tag that indicates whether the `step` is for training, validation, or testing. It unpacks the batch into the support and query sets, then uses the PrototypicalNet to make predictions on the query set. It computes the loss and evaluation metrics, and logs the output dictionary. The `training_step`, `validation_step`, and `test_step` methods simply call the step method with the appropriate tag.\n",
    "\n",
    "The `step` method is where the majority of the logic for training the model resides. It is here that we make predictions with the PrototypicalNet, compute the loss and evaluation metrics, and log the output. By defining a separate `step` method, we can easily reuse this logic for the training, validation, and testing steps.\n",
    "\n",
    "```python\n",
    "def step(self, batch, batch_idx, tag: str):\n",
    "    support, query = batch\n",
    "\n",
    "    logits = self.protonet(support, query)\n",
    "    loss = self.loss(logits, query[\"target\"])\n",
    "\n",
    "    output = {\"loss\": loss}\n",
    "    for k, metric in self.metrics.items():\n",
    "        output[k] = metric(logits, query[\"target\"])\n",
    "\n",
    "    for k, v in output.items():\n",
    "        self.log(f\"{k}/{tag}\", v)\n",
    "    return output\n",
    "\n",
    "def training_step(self, batch, batch_idx):\n",
    "    return self.step(batch, batch_idx, \"train\")\n",
    "\n",
    "def validation_step(self, batch, batch_idx):\n",
    "    return self.step(batch, batch_idx, \"val\")\n",
    "\n",
    "def test_step(self, batch, batch_idx):\n",
    "    return self.step(batch, batch_idx, \"test\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the code below to see the full implementation of the `FewShotLearner` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "class FewShotLearner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "        protonet: nn.Module, \n",
    "        learning_rate: float = 1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.protonet = protonet\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.metrics = nn.ModuleDict({\n",
    "            'accuracy': Accuracy()\n",
    "        })\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def step(self, batch, batch_idx, tag: str):\n",
    "        support, query = batch\n",
    "\n",
    "        logits = self.protonet(support, query)\n",
    "        loss = self.loss(logits, query[\"target\"])\n",
    "\n",
    "        output = {\"loss\": loss}\n",
    "        for k, metric in self.metrics.items():\n",
    "            output[k] = metric(logits, query[\"target\"])\n",
    "\n",
    "        for k, v in output.items():\n",
    "            self.log(f\"{k}/{tag}\", v)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together -- Training the Model\n",
    "\n",
    "Now that we have defined the `FewShotLearner` class, we can instantiate it and train the model. We'll use the `Trainer` class from PyTorch Lightning to train the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FewShotLearner(\n",
      "  (protonet): PrototypicalNet(\n",
      "    (backbone): Backbone(\n",
      "      (melspec): MelSpectrogram(\n",
      "        (spectrogram): Spectrogram()\n",
      "        (mel_scale): MelScale()\n",
      "      )\n",
      "      (conv1): ConvBlock(\n",
      "        (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (gn): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (relu): ReLU()\n",
      "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv2): ConvBlock(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (gn): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "        (relu): ReLU()\n",
      "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv3): ConvBlock(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (gn): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (relu): ReLU()\n",
      "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv4): ConvBlock(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (gn): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
      "        (relu): ReLU()\n",
      "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv5): ConvBlock(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
      "        (gn): GroupNorm(128, 512, eps=1e-05, affine=True)\n",
      "        (relu): ReLU()\n",
      "        (maxpool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss): CrossEntropyLoss()\n",
      "  (metrics): ModuleDict(\n",
      "    (accuracy): Accuracy()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/conda/envs/hugo/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'protonet' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['protonet'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "learner = FewShotLearner(protonet)\n",
    "print(learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below will train the model for as many episodes are in the training episode dataset. On a GPU, training should take anytime between 20 minutes to an hour. \n",
    "\n",
    "Note that the Lightning Trainer will automatically log the loss and metrics to Tensorboard. You can view the Tensorboard logs by running the following command in the terminal:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profiler import SimpleProfiler\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    max_epochs=1,\n",
    "    log_every_n_steps=1, \n",
    "    val_check_interval=50,\n",
    "    profiler=SimpleProfiler(\n",
    "        filename=\"profile.txt\",\n",
    "    ), \n",
    "    logger=TensorBoardLogger(\n",
    "        save_dir=\".\",\n",
    "        name=\"logs\"\n",
    "    ), \n",
    ")\n",
    "\n",
    "# train!\n",
    "trainer.fit(learner, train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your model has finished training, the Trainer will save the model checkpoint to the `logs` directory. In the final chapter of this coding tutorial, we'll load our trained model, evaluate it on our evaluation set, and visualize the embedding space of our prototypical network. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('hugo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec27501cbbac6acacfd09d8db1502718360d0cdb5a917685adcae650b3d3518d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
