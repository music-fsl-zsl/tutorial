
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Zero-shot learning task formulation &#8212; Few-shot and Zero-shot Learning for Music Information Retrieval</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Side Information" href="03_side_information.html" />
    <link rel="prev" title="Optimization-Based Few-Shot Learning" href="../foundations-fsl/optimization-based-fsl.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Few-shot and Zero-shot Learning for Music Information Retrieval</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing.html">
                    Few-Shot and Zero-Shot Learning for Music Information Retrieval
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/fsl-and-zsl.html">
   What are Few-Shot Learning (FSL) and Zero-Shot Learning (ZSL)?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/advantages.html">
   Advantages of FSL and ZSL in MIR
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations: Few-Shot Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../foundations-fsl/foundations.html">
   Few-Shot Learning Foundations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../foundations-fsl/approaches.html">
   Approaches
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../foundations-fsl/metric-based-fsl.html">
   Metric-Based Few-Shot Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../foundations-fsl/optimization-based-fsl.html">
   Optimization-Based Few-Shot Learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Foundations: Zero-Shot Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Zero-shot learning task formulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_side_information.html">
   Side Information
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Few-Shot Learning in PyTorch
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../fsl-example/intro.html">
   Introduction: Few-Shot Learning in PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fsl-example/datasets.html">
   Building a Class-Conditional Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fsl-example/episodes.html">
   Sampling Few-Shot Learning Episodes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fsl-example/models.html">
   Building a Prototypical Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fsl-example/training.html">
   Training a Few-Shot Instrument Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fsl-example/evaluating.html">
   Evaluating (and Visualizing) a Trained Prototypical Net
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Advances
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../advances/introduction.html">
   Recent Advances in MIR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advances/classification.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advances/classification_zsl.html">
   Zero-shot Music Tagging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advances/source-sep.html">
   Music Source Separation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advances/transcription.html">
   Drum Transcription
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/music-fsl-zsl/tutorial"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/music-fsl-zsl/tutorial/issues/new?title=Issue%20on%20page%20%2Ffoundations-zsl/02_task_formulation.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/foundations-zsl/02_task_formulation.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Zero-shot learning task formulation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem-definition">
     Problem definition
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modeling-f">
     Modeling
     <span class="math notranslate nohighlight">
      \(f\)
     </span>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-objectives-for-zero-shot-learning">
     Training objectives for zero-shot learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximizing-the-compatibility">
       (1) Maximizing the compatibility.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#minimizing-a-distance-loss-function-metric-learning-approach">
       (2) Minimizing a distance loss function (metric learning approach).
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#available-data-while-training">
     Available data while training
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zero-shot-evlauation-scheme">
   Zero-shot evlauation scheme
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalized-zero-shot-evaluation-setup">
     ‘Generalized’ zero-shot evaluation setup
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#different-approaches-for-zero-shot-learning">
   Different approaches for zero-shot learning
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-1-learning-by-pairwise-ranking-of-compatibility">
     (1) Case 1 : Learning by pairwise ranking of compatibility
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-2-learning-by-maximizing-probability-function">
     (2) Case 2 : Learning by maximizing probability function
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-3-autoencoder-approach">
     (3) Case 3 : Autoencoder approach
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-4-generative-approach">
     (4) Case 4 : Generative approach
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Zero-shot learning task formulation</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Zero-shot learning task formulation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem-definition">
     Problem definition
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modeling-f">
     Modeling
     <span class="math notranslate nohighlight">
      \(f\)
     </span>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-objectives-for-zero-shot-learning">
     Training objectives for zero-shot learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximizing-the-compatibility">
       (1) Maximizing the compatibility.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#minimizing-a-distance-loss-function-metric-learning-approach">
       (2) Minimizing a distance loss function (metric learning approach).
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#available-data-while-training">
     Available data while training
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zero-shot-evlauation-scheme">
   Zero-shot evlauation scheme
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalized-zero-shot-evaluation-setup">
     ‘Generalized’ zero-shot evaluation setup
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#different-approaches-for-zero-shot-learning">
   Different approaches for zero-shot learning
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-1-learning-by-pairwise-ranking-of-compatibility">
     (1) Case 1 : Learning by pairwise ranking of compatibility
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-2-learning-by-maximizing-probability-function">
     (2) Case 2 : Learning by maximizing probability function
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-3-autoencoder-approach">
     (3) Case 3 : Autoencoder approach
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#case-4-generative-approach">
     (4) Case 4 : Generative approach
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="zero-shot-learning-task-formulation">
<h1>Zero-shot learning task formulation<a class="headerlink" href="#zero-shot-learning-task-formulation" title="Permalink to this headline">#</a></h1>
<p>Now, we’ll go over more detailed formulation of zero-shot learning. Basic task formulation of zero-shot learning frames work is as follows.</p>
<section id="problem-definition">
<h2>Problem definition<a class="headerlink" href="#problem-definition" title="Permalink to this headline">#</a></h2>
<p>Given a dataset of input feature vectors <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and their associated labels <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, we first split the class labels into seen and unseen groups (<span class="math notranslate nohighlight">\(\mathcal{Y}^{seen}\)</span>, <span class="math notranslate nohighlight">\(\mathcal{Y}^{unseen}\)</span>). The resulted ‘seen’ split is composed of <span class="math notranslate nohighlight">\(\mathcal{S}^{seen}\equiv\{\left(x_n, y_n\right)\}_{n=1}^{N}\)</span>, where an input <span class="math notranslate nohighlight">\(x_n\)</span> is a feature vector on a <span class="math notranslate nohighlight">\(D\)</span>-dimensional space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> (<span class="math notranslate nohighlight">\(x_n \in \mathcal{X} \stackrel{\text{def}}{=}\mathbb{R}^D\)</span>) and <span class="math notranslate nohighlight">\(y_n\)</span> is one of <span class="math notranslate nohighlight">\(C_0\)</span> label classes (  <span class="math notranslate nohighlight">\(y_n \in \mathcal{Y}^{seen} \equiv\left\{1, \ldots, C_0\right\}\)</span>).</p>
<p>The other set is denoted as the <em>unseen</em> split <span class="math notranslate nohighlight">\(\mathcal{S}^{unseen} \equiv\left\{\left(x_n^{\prime}, y_n^{\prime}\right)\right\}_{n=1}^{N^{\prime}}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{x}_n^{\prime}\)</span> is also a vector from the feature space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> (<span class="math notranslate nohighlight">\(x_n^{\prime} \in \mathcal{X}\)</span>), while <span class="math notranslate nohighlight">\(y_n^{\prime}\)</span> is from the other set of classes (<span class="math notranslate nohighlight">\(y_n^{\prime} \in \mathcal{Y}^{unseen} \equiv\)</span> <span class="math notranslate nohighlight">\(\left\{C_0+1, \ldots, C_0+C_1\right\}\)</span>). Note that <span class="math notranslate nohighlight">\(\mathcal{Y}^{seen} \cap \mathcal{Y}^{unseen}=\varnothing\)</span>.</p>
<p>To simulate a zero-shot condition where the model is supposed to infer an input to a novel class,  only a subset of input and ‘seen’ label pairs (<span class="math notranslate nohighlight">\(\mathcal{S}^{seen}\)</span>) are used in training.
At test time, the other subset of the input and ‘unseen’ label pairs (<span class="math notranslate nohighlight">\(\mathcal{S}^{unseen}\)</span>) are used for evaluation.</p>
<p>Another main ingredient for the zero-shot model is the side information, which is often given as an additional representational space of the label classes, <span class="math notranslate nohighlight">\(\{\phi(y) ; y \in \mathcal{Y}^{seen} \cup \mathcal{Y}^{unseen}\}\)</span>, where
<span class="math notranslate nohighlight">\(\phi(y) \in \Phi \equiv \mathbb{R}^{D^{\prime}}\)</span>.</p>
<p>The goal of zero-shot learning is to learn a classfier <span class="math notranslate nohighlight">\(f: \mathcal{X} \rightarrow \mathcal{Y}\)</span>  that is well-generalized to <span class="math notranslate nohighlight">\(\mathcal{Y}^{unseen}\)</span> even without seeing any training instances for <span class="math notranslate nohighlight">\(\mathcal{Y}^{unseen}\)</span> (<span class="math notranslate nohighlight">\(\mathcal{Y}^{seen} \subset \mathcal{Y}, \mathcal{Y}^{unseen} \subset \mathcal{Y}\)</span>),.</p>
<p>To summarize, given <span class="math notranslate nohighlight">\(\mathcal{S^{seen}}=\left\{\left(x_n, y_n\right), n=1 \ldots N\right\}\)</span>, with <span class="math notranslate nohighlight">\(x_n \in \mathcal{X}^{seen}\)</span> and <span class="math notranslate nohighlight">\(y_n \in \mathcal{Y}^{seen}\)</span>, where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal{S}^{seen}\)</span> refers to the set of seen input vectors and their associated classes.</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathcal{Y^{seen}}\)</span> is the set of seen classes.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{X^{seen}}\)</span> is the set of input vectors that are paired with the seen classes.</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(x_n\)</span> is a <span class="math notranslate nohighlight">\(D\)</span>-dimensional input vector in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> (<span class="math notranslate nohighlight">\(x_n \in \mathcal{X} \stackrel{\text{def}}{=}\mathbb{R}^D\)</span>).</p></li>
<li><p><span class="math notranslate nohighlight">\(y_n \in \{1,...,C_0\}\)</span> is the class label that corresponds to <span class="math notranslate nohighlight">\(x_n\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(N\)</span> is the size of the seen training pairs.</p></li>
</ul>
<p>we learn <span class="math notranslate nohighlight">\(f: \mathcal{X} \rightarrow \mathcal{Y}\)</span> by minimizing the regularized loss function :</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{N} \sum_{n=1}^N L\left(y_n, f\left(x_n ; W\right)\right)+\Omega(W)
\]</div>
<p>, where <span class="math notranslate nohighlight">\(L()\)</span> is a loss function and <span class="math notranslate nohighlight">\(\Omega()\)</span> is a regularization term.</p>
<p>This looks quite similar to a classical supervised learning process, however, the model should be able to make predictions for the general class set <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. At the test phase, the model makes prediction on inputs that are associated with the unseen label set <span class="math notranslate nohighlight">\(\mathcal{Y^{unseen}}\)</span> by calculating the maximum compatibility.</p>
</section>
<section id="modeling-f">
<h2>Modeling <span class="math notranslate nohighlight">\(f\)</span><a class="headerlink" href="#modeling-f" title="Permalink to this headline">#</a></h2>
<p><span class="math notranslate nohighlight">\(f\)</span> is usually modeled by using a certain compatibility function :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(x ; W)=\underset{y \in \mathcal{Y}}{\operatorname{argmax}}F(x, y ; W)\)</span>, where <span class="math notranslate nohighlight">\(F(x, y ; W)\)</span> is a compatibility function that measures how compatible the input is with a class label.</p></li>
</ul>
<p>Since inputs and labels are represented as vectors <span class="math notranslate nohighlight">\(\theta(x), \phi(y)\)</span> using corresponding embedding functions,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> is a representational embedding function for input features.</p></li>
<li><p><span class="math notranslate nohighlight">\(\phi\)</span> is a representational embedding function for class labels as described abolve.</p></li>
</ul>
<p>taking the <span class="math notranslate nohighlight">\(\argmax_{y \in \mathcal{Y}}\)</span> of compatibility is often acheived by choosing the nearest neighbor vector on the embedding space.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F(x, y ; W)\)</span> can be rewritten as <span class="math notranslate nohighlight">\(F^{\prime}(\theta(x), \phi(y) ; W)\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(W\)</span> is a learnable matrix (our model).</p></li>
</ul>
<p>And when dealing with explicit attribute annotations for each class, <span class="math notranslate nohighlight">\(f\)</span> can also be modeled in a more explicit fashion. Given explicit attribute classes <span class="math notranslate nohighlight">\(a \in A\)</span>, where <span class="math notranslate nohighlight">\(A\equiv \{1, \ldots, M\}\)</span>, <span class="math notranslate nohighlight">\(f\)</span> can be modeled using the combination of the conditional probabilities of attributes given the input feature.</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(f(x)=\underset{y \in \mathcal{Y}}{\operatorname{argmax}} \prod_{m=1}^M \frac{p\left(a_m^y \mid x\right)}{p\left(a_m^y\right)}\)</span>.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M\)</span> : number of attributes</p></li>
<li><p><span class="math notranslate nohighlight">\(a_m^y\)</span> is the m-th attribute of class <span class="math notranslate nohighlight">\(y\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p\left(a_m^y \mid x\right)\)</span> is the attribute probability given input <span class="math notranslate nohighlight">\(x\)</span> which is obtained from the attribute classifiers (our estimator).</p></li>
<li><p><span class="math notranslate nohighlight">\(p\left(a_m^y\right)\)</span> is the attribute prior estimated by the empirical mean of attributes over training classes.</p></li>
</ul>
</li>
<li><p>Reference : Direct Attribute Projection (DAP) and Indirect Attribute Projection (IAP), 2009.</p>
<ul>
<li><img src = "../assets/zsl/DAP.png" width=800>
</li>
</ul>
</li>
</ul>
</section>
<section id="training-objectives-for-zero-shot-learning">
<h2>Training objectives for zero-shot learning<a class="headerlink" href="#training-objectives-for-zero-shot-learning" title="Permalink to this headline">#</a></h2>
<section id="maximizing-the-compatibility">
<h3>(1) Maximizing the compatibility.<a class="headerlink" href="#maximizing-the-compatibility" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>e.g. Linear compatibility function (learnable)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(F(x, y ; W)=\theta(x)^T W \phi(y)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> is a representational embedding function for input features.</p></li>
<li><p><span class="math notranslate nohighlight">\(\phi\)</span> is a representational embedding function for class labels as described abolve.</p></li>
</ul>
</li>
<li><p>This can also be seen as learning a projection matrix that maximizes the dot product.</p></li>
</ul>
</li>
</ul>
<p>or by</p>
</section>
<section id="minimizing-a-distance-loss-function-metric-learning-approach">
<h3>(2) Minimizing a distance loss function (metric learning approach).<a class="headerlink" href="#minimizing-a-distance-loss-function-metric-learning-approach" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Nonlinear mapping function (neural network layer <span class="math notranslate nohighlight">\(W_1\)</span> and <span class="math notranslate nohighlight">\(W_2\)</span>) trained with a loss function</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\sum_{y \in \mathcal{Y}^{seen}} \sum_{x \in \mathcal{X}_y} \| \phi(y)-W_1 \tanh \left(W_2 \cdot \theta(x)\right) \|^2\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> is a representational embedding function for input features.</p></li>
<li><p><span class="math notranslate nohighlight">\(\phi\)</span> is a representational embedding function for class labels as described abolve.</p></li>
</ul>
</li>
<li><p>Other distance metrics such as cosine distance can also be used.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="available-data-while-training">
<h2>Available data while training<a class="headerlink" href="#available-data-while-training" title="Permalink to this headline">#</a></h2>
<p>To simulate a proper zero-shot learning situation, unseen classes should be strictly blinded during training phase.
However, depending on the scope of information that the zero-shot model sees during training, there are two broad types of setup. One is inductive zero-shot learning and the other is transductive zero-shot learning.
In transductive learning setup, in addition to the seen classes and their labeled data samples, the model takes unlabeled data samples from the unseen classes into account. This alleviates the projection domain shift problem by letting the model catch the distribution of unseen class instances and learn a more discriminative projection.</p>
<ul class="simple">
<li><p>Inductive zero-shot learning</p>
<ul>
<li><p>A common setup is the inductive zero-shot learning. In this approaches, only labeled training samples and auxiliary information of seen classes are available during training.</p></li>
</ul>
</li>
<li><p>Transductive zero-shot learning</p>
<ul>
<li><p>Labeled training samples, unlabelled test samples, and auxiliary information of all classes are available during training.</p></li>
</ul>
</li>
</ul>
<img src = "../assets/zsl/inductive_transductive.png" width=1000>
<!-- A schematic diagram of ZSL versus GZSL. Assume that the seen class contains samples of Otter and Tiger, while the unseen class contains samples of Polar bear and Zebra. (a) During the training phase, both GZSL and ZSL methods have access to the samples and semantic representations of the seen class. (b) During the test phase, ZSL can only recognize samples from the unseen class, while (c) GZSL is able to recognize samples from both seen and unseen classes. -->
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="zero-shot-evlauation-scheme">
<h1>Zero-shot evlauation scheme<a class="headerlink" href="#zero-shot-evlauation-scheme" title="Permalink to this headline">#</a></h1>
<section id="generalized-zero-shot-evaluation-setup">
<h2>‘Generalized’ zero-shot evaluation setup<a class="headerlink" href="#generalized-zero-shot-evaluation-setup" title="Permalink to this headline">#</a></h2>
<p>In conventional zero-shot learning setup, the trained model was evaluated on the set of unseen classes and their associated data samples. Under this formulation,conventional zero-shot learning research have verified that the basic concept of zero-shot knowledge transfer actually works.</p>
<p>However, in the real world problem, the practical advantage of zero-shot learning is in its generalizability where the prediction scope can expand to a large number of classes present on the side information space. To strictly verify this cabability, the ‘generalized’ zero-shot evaluation had been proposed. Since zero-shot learning models are prone to overfit on the seen classes, they often perform poorly under the generalized zero-shot learning setup.</p>
<p>Since then, generalized zero-shot evaluation became the standard criterion of zero-shot model performance.</p>
<img src = "../assets/zsl/zsl_vs_gzsl.png" width=800>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="different-approaches-for-zero-shot-learning">
<h1>Different approaches for zero-shot learning<a class="headerlink" href="#different-approaches-for-zero-shot-learning" title="Permalink to this headline">#</a></h1>
<section id="case-1-learning-by-pairwise-ranking-of-compatibility">
<h2>(1) Case 1 : Learning by pairwise ranking of compatibility<a class="headerlink" href="#case-1-learning-by-pairwise-ranking-of-compatibility" title="Permalink to this headline">#</a></h2>
<p>DeViSE: A Deep Visual-Semantic Embedding Model (Frome et al., 2013)</p>
<p>Maximize the following objective function using pairwise ranking:</p>
<div class="math notranslate nohighlight">
\[
\sum_{y \in \mathcal{Y}^{t r}}\left[\Delta\left(y_n, y\right)+F\left(x_n, y ; W\right)-F\left(x_n, y_n ; W\right)\right]_{+}
\]</div>
<ul class="simple">
<li><p>Ranking objective to map training inputs close to continuous embedding vectors corresponding to correct labels.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Delta\left(y_n, y\right)=1\)</span> if <span class="math notranslate nohighlight">\(y_n=y\)</span>, otherwise 0</p></li>
<li><p>Optimized by gradient descent.</p></li>
</ul>
</section>
<section id="case-2-learning-by-maximizing-probability-function">
<h2>(2) Case 2 : Learning by maximizing probability function<a class="headerlink" href="#case-2-learning-by-maximizing-probability-function" title="Permalink to this headline">#</a></h2>
<p>Learning to detect unseen object classes by between-class attribute transfer (Lampert et al., 2009)</p>
<p>CONSE (Norouzi et al., 2014)</p>
<p>Instead of learning the mapping function <span class="math notranslate nohighlight">\(f: \mathcal{X} \rightarrow \mathcal{Y}\)</span> explicitly, learn a classifier from training inputs to seen labels. The probability of an input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> belonging to a class label <span class="math notranslate nohighlight">\(y \in \mathcal{Y}_{seen}\)</span> can then be estimated, denoted <span class="math notranslate nohighlight">\(p_{seen}(y \mid x)\)</span>, where <span class="math notranslate nohighlight">\(\sum_{y=1}^{n} p_{seen}(y \mid x)=1\)</span>.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(x, t)\)</span> : <span class="math notranslate nohighlight">\(\mathrm{t}^{th}\)</span> most likely label for input <span class="math notranslate nohighlight">\(x\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(f(x, 1) \equiv \underset{y \in \mathcal{Y}_{seen}}{\operatorname{argmax}} p_{seen}(y \mid x)\)</span> : probability of an input <span class="math notranslate nohighlight">\(x\)</span> belonging to a seen class:</p></li>
</ul>
</li>
<li><p>Each class label <span class="math notranslate nohighlight">\(y(1 \leq y \leq n)\)</span> is associated with a semantic embedding vector <span class="math notranslate nohighlight">\(\phi(y) \in \Phi \equiv \mathbb{R}^{D^{\prime}}\)</span>.</p></li>
<li><p>Given a test input, the ConSE simply runs the convolutional classifier and considers the top T predictions of the model. Then, the convex combination of the corresponding <span class="math notranslate nohighlight">\(T\)</span> semantic embedding vectors in the semantic space is computed, which defines a deterministic transformation from the outputs of the Softmax classifier into the embedding space.</p></li>
</ul>
<p>Combination of semantic embeddings <span class="math notranslate nohighlight">\((\phi)\)</span> is used to assign an unknown input to an unseen class:</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{Z} \sum_{i=1}^T p_{seen}(f(x, t) \mid x) \phi(f(x, t))
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Z \)</span>: normalization factor given by <span class="math notranslate nohighlight">\(Z=\sum_{i=1}^T p_{seen}(f(x, t) \mid x)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T\)</span> : hyperparameter of controlling the maximum number of semantic embedding vectors to be considered.</p></li>
</ul>
<p>If the classifier is confident in its prediction of a label <span class="math notranslate nohighlight">\(y\)</span> for <span class="math notranslate nohighlight">\(x\)</span>, i.e., <span class="math notranslate nohighlight">\(p_{seen}(y \mid x) \approx 1\)</span>, then <span class="math notranslate nohighlight">\(f(x) \approx \phi(y)\)</span>. If not, predicted semantic embedding is somewhere between <span class="math notranslate nohighlight">\(T\)</span> most likely classes (weighted-sum).</p>
</section>
<section id="case-3-autoencoder-approach">
<h2>(3) Case 3 : Autoencoder approach<a class="headerlink" href="#case-3-autoencoder-approach" title="Permalink to this headline">#</a></h2>
<p>SAE (Kodirov et al., 2017)
Minimize the reconstruction loss (similar to the linear auto-encoder).</p>
<div class="math notranslate nohighlight">
\[
\min _W\left\|\theta(x)-W^T \phi(y)\right\|^2+\lambda\|W \theta(x)-\phi(y)\|^2,
\]</div>
<ul class="simple">
<li><p>Learns a linear projection from <span class="math notranslate nohighlight">\(\theta(x)\)</span> to <span class="math notranslate nohighlight">\(\phi(y)\)</span>, being similar to above approaches.</p></li>
<li><p>Reconstruction of the original input embedding is set as the training objective .</p></li>
</ul>
</section>
<section id="case-4-generative-approach">
<h2>(4) Case 4 : Generative approach<a class="headerlink" href="#case-4-generative-approach" title="Permalink to this headline">#</a></h2>
<p>f-CLSWGAN (Xian et al., 2017)</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./foundations-zsl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../foundations-fsl/optimization-based-fsl.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Optimization-Based Few-Shot Learning</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="03_side_information.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Side Information</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Yu Wang, Hugo Flores García, and Jeong Choi<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>